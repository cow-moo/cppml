#include <iostream>
#include "test.hpp"
#include "tensor.hpp"
#include "autograd.hpp"
#include "module.hpp"
//#include "include/model.hpp"
//#include "include/tensor.hpp"

using linalg::Tensor;
using autograd::Expression;

void test_creation() {
    Tensor<float> t1 = Tensor<float>::zeros({2, 3});
    assert(t1.shape == std::vector<size_t>({2, 3}));
    
    Tensor<float> t2({{1, 2, 3}, {4, 5, 6}});
    assert(t2.shape == std::vector<size_t>({2, 3}));
}

void test_indexing() {
    Tensor<float> t({{1, 2, 3}, {4, 5, 6}});
    assert((float)(t[0, 1]) == 2);
    t[1, 2] = 10;
    assert((float)(t[1, 2]) == 10);
}

void test_broadcasting() {
    Tensor<float> t1({1, 2, 3});
    Tensor<float> t2({{1, 2, 3}, {4, 5, 6}});
    Tensor<float> res = t1 + t2;
    assert(res.shape == std::vector<size_t>({2, 3}));
}

void test_elementwise_ops() {
    Tensor<float> t1({1, 2, 3});
    Tensor<float> t2({4, 5, 6});
    assert(((t1 + t2)[1]) == 7);
    assert(((t1 - t2)[1]) == -3);
    assert(((t1 * t2)[1]) == 10);
    assert(((t1 / t2)[1]) == 2.0f / 5);
}

void test_sum() {
    Tensor<float> t({{1, 2, 3}, {4, 5, 6}});
    Tensor<float> s = t.sum(0);
    assert(s.shape == std::vector<size_t>({3}));
    assert((float)s[1] == 7);
}

void test_reshape() {
    Tensor<float> t({{1, 2, 3}, {4, 5, 6}});
    Tensor<float> r = t.reshape({3, 2});
    assert(r.shape == std::vector<size_t>({3, 2}));
}

void test_matmul() {
    Tensor<float> a({{1, 2}, {3, 4}});
    Tensor<float> b({{5, 6}, {7, 8}});
    Tensor<float> c = Tensor<float>::matmul(a, b);
    assert(c.shape == std::vector<size_t>({2, 2}));
    assert((float)(c[0, 0]) == 19);
    assert((float)(c[1, 1]) == 50);
}


void run_tests() {
    test_creation();
    test_indexing();
    test_broadcasting();
    test_elementwise_ops();
    test_sum();
    test_reshape();
    test_matmul();
    
    std::cout << "All tests passed!" << std::endl;
}

int main() {
    run_tests();
    Expression<> a({1, 2, 3}, true), b({4, 5, 6}, true);
    a.value().print();
    b.value().print();
    Expression<> sum = (a + b).sum();
    sum.value().print();

    sum.backward();
    a.grad().print();
    b.grad().print();

    return 0;
}

// class TwoLayerNet : public Model {
//     TwoLayerNet(Tensor)
// };

// int main() {
//     linalg::Tensor<> a({1, 2, 3});
//     linalg::Tensor<> b({5});
//     //linalg::Tensor<> c = a + b;
//     (a + b).print();
//     // A a;
//     // a.test();
//     // models::Sequential twoLayerNet(3, {layers::Linear(8), layers::ReLU(), layers::Linear(1)}, solver::GradientDescent(0.01), solver::MSE());
//     // twoLayerNet.fit();
// }

/*
TODO
- modules build the computation graph and hold weights/submodules between passes
- implement sum across abritrary axes
- expression class that holds n expression pointers
 - base case is expression that holds a tensor (Parameter)
 - forward pass sets up expression objects, computes final loss fn
 - backprop on loss function traverses the tree generated by expression classes and propagates
 - each expression must cache output as well as gradient of loss wrt output
 - 2 solutions for backprop order
  - compute how many "parent" expressions there are during graph construction. during DFS from loss expression, decrement count whenever expression is reached.
    then, only call backward() when count reaches zero
  - during graph construction, maintain linked list in topo sort order that splices lists from child expressions. then, during backprop iterate through list
 - use concept for expressions
  - value() -> Tensor& (computed and cached on construction)
  - gradient() -> Tensor* (nullptr if doesn't require gradient)
  - backward() (uses cached gradient here and propagates to childrens' gradient caches)
  - other fields
   - value cache (computed and initialized on construction)
   - gradient cache (if gradient is required, initialized to zero)
   - number of parents? or linked list of this expression and child expressions in topo order
 - actually lwk could make this template using this trick for forwards and backwards with pack arguments:
    constexpr auto lambda = [](int a) { return a * 2; }; 
    using U = T<lambda>;
    or T<decltype([](int a) { return a * 2; }){}> obj;

    template<auto forward, auto backward, typename Args...>
    class Expression {};

    template<typename U, typename V>
    AddExpr = Expression<[](Tensor& a, Tensor& b) { return a + b; }, [](Tensor& grad, Tensor* a, Tensor* b) { *a += grad, *b += grad; }, U, V>;
 - store list of learnable Parameters, zero out and use in expressions each time loss is computed. then optimizer does things with Parameter's value and gradient
 - how do we deal with rvalue lvalue? use universal reference T&& and forward() into some processing overload for rvalue and lvalue
  - rvalue should be moved into reference, lvalue should be saved
  - nvm doesnt work, rvalues cannot be moved into reference fields
 - make wrapper class Expression that contains Node pointer
  - allows stuff like x = x + y and means we don't have pointers to stack variables
- consider doing template <auto op> for passing functions. does not allow capture however
- simd: during axes recursion stop when subtensors are full (stored contiguously) and do simd operations
 - scalar operations should have built in operations to broadcast. research further
 - when broadcasting, do profiling for relative size between tensors. can try striding and adding or adding smaller tensor many times
 - think about when both tensors are being duplicated
 - could also stop earlier when theres a fixed stride (iff tail axes are fixed?)
 - use neon
- try to join consecutive operations? a + (b * 2) gets evaluated once
- random init
- implement tail recursion elimination
- research how to optimize/parallelize these elementwise operations
- .sum()
- figure out scalar operations
- matmul
- reshape
 - might need to do copy operations when slices occur
 - in place or return?
- numpy also does copies when doing arbitrary slices, seems to also keep views with Range objects
- figure out elementwise assignment (make TensorSlice class with elementwise assignment and Tensor conversion operator for implicit casting?)
- idea: make the TensorSlice class just modify indexing in place? (doesn't really work)
- other idea: have elementwise operation just keep track of running index offsets so it doesn't need to make new Tensor slices
 - probably more correct
- main problem is that we're copying axisIndices/shape which mostly aren't changing and shared ptr data overhead?
*/